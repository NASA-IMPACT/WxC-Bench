{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882b176f-0eab-4b23-9845-f267721700de",
   "metadata": {},
   "source": [
    "# Forecast evaluation\n",
    "\n",
    "This notebook evaluates the machine-learning-based S2S preciptation forecasts against the ECMWF baseline and a monthly precipitation climatology.\n",
    "\n",
    "The evaluation expects the forecasts results to be organized in separate folders containing the forecasts in files separated by initialization date. The files should follow the filename pattern ``*_YYYYMMDD_00_00.nc`` where ``YYYYMMDD`` specifies the initialization date of the forecast, i.e., the first day for which a forecast is produced. Each file should contain the predicted daily precipitation accumulations on the MERRA grid as three-dimensional field with dimensions ``step``, ``latitude``, ``longitude``.\n",
    "\n",
    "\n",
    "The ``DATA_PATH`` variable defined in the cell below should be set to the path containing the ``training_data`` and ``test_data`` folders of the 2S2-Precip dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54cb7c8-d8ba-4f8d-9175-fa5595afcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_PATH = Path(\"/edata1/simon/chimp/s2s/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40e17e-d0da-44bd-aa81-0928cef29a7b",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "The code below defines helper functions to load forecasts results for a given initialization time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac3338-24a3-48d3-95d0-6b4268bf9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from pansat.time import to_datetime\n",
    "\n",
    "def find_file(date: np.datetime64, path: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Find a result file for a given date.\n",
    "\n",
    "    Args:\n",
    "        date: The initialization dat.\n",
    "        path: The folder containing the files.\n",
    "\n",
    "    Result:\n",
    "        A path object pointing to the file expected to contain the results for the given date.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    date = to_datetime(date)\n",
    "    date_str = date.strftime(\"%Y%m%d_%H_%M\")\n",
    "    pattern =  f\"*_{date_str}.nc\"\n",
    "    files = sorted(list(path.glob(pattern)))\n",
    "    if len(files) == 0:\n",
    "        raise RuntimeError(\n",
    "            f\"Didn't find any file in '{path}' for the given date {date}.\"\n",
    "        )\n",
    "    if len(files) > 1:\n",
    "        raise RuntimeError(\n",
    "            f\"Found multiple files in '{path}' for the given date {date}.\"\n",
    "        )\n",
    "    return files[0]\n",
    "\n",
    "def load_reference_data(start_date: np.datetime64, path: Path, n_days: int = 28):\n",
    "    \"\"\"\n",
    "    Load the reference data for forecasts initialized at a given date.\n",
    "\n",
    "    Args:\n",
    "        start_date: The initialization time of the forecast.\n",
    "        path: Path to the directory containing the reference data.\n",
    "        n_days: The number of consecutuve days for which to load the reference data starting\n",
    "             with the start date.\n",
    "\n",
    "    Return:\n",
    "        An xarray.Dataset containing the reference data fields.\n",
    "    \"\"\"\n",
    "    ref_data = []\n",
    "    date = start_date\n",
    "    steps = np.arange(0, n_days).astype(\"timedelta64[D]\")\n",
    "    for date in start_date + steps:\n",
    "        data = xr.load_dataset(find_file(date, path))\n",
    "        precip = data.precipitation.data\n",
    "        precip[precip < 0.0] = np.nan\n",
    "        ref_data.append(data)\n",
    "    ref_data = xr.concat(ref_data, \"step\")\n",
    "    ref_data[\"step\"] = steps.astype(\"timedelta64[ns]\")\n",
    "    ref_data[\"time\"] = start_date.astype(\"datetime64[ns]\")\n",
    "    return ref_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3785a-e4fb-4cf7-adc9-22b7a290cedb",
   "metadata": {},
   "source": [
    "### Load or calculate climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136b10f-fcd5-4b79-9d1b-20748d052e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from chimp.areas import MERRA\n",
    "\n",
    "def calculate_precip_climatology(precip_data: Path) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Calculate precipitation climatology from daily accumulation files.\n",
    "\n",
    "    Args:\n",
    "        precip_data: A path object pointing to the reference precipitation data from which\n",
    "             to compute the climatolog.\n",
    "\n",
    "    Return:\n",
    "        An xarray.Dataset containing the monthly climatology.\n",
    "    \"\"\"\n",
    "    precip_data = Path(precip_data)\n",
    "    \n",
    "    files = sorted(list(precip_data.glob(\"*_20??????_??_??.nc\")))\n",
    "\n",
    "    tot_precip = np.zeros((12,) + MERRA[8].shape)\n",
    "    counts = np.zeros((12,) + MERRA[8].shape)\n",
    "\n",
    "    print(\"Calculating climatology:\")\n",
    "    for path in tqdm(files):\n",
    "        with xr.open_dataset(path) as data:\n",
    "\n",
    "            data = data.transpose(\"latitude\", \"longitude\")\n",
    "            month = int(path.name.split(\"_\")[1][4:-2])\n",
    "            lons = data.longitude.data\n",
    "            lats = data.latitude.data\n",
    "            \n",
    "            precipitation = data.precipitation.data\n",
    "            valid = np.isfinite(precipitation) * (precipitation >= 0)\n",
    "            tot_precip[month - 1][valid] += precipitation[valid]\n",
    "            counts[month - 1] += valid.astype(\"float32\")\n",
    "\n",
    "    climatology = xr.Dataset({\n",
    "        \"month\": ((\"month\",), np.arange(12) + 1),\n",
    "        \"longitude\": ((\"longitude\",), lons),\n",
    "        \"latitude\": ((\"latitude\",), lats),\n",
    "        \"precipitation\": ((\"month\", \"latitude\", \"longitude\"), tot_precip / counts)\n",
    "    })\n",
    "    return climatology\n",
    "                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a91acb-78c7-45ca-a118-ad4d0d9e6937",
   "metadata": {},
   "source": [
    "Below, a montly precipitation climatology from a file called ``climatology.nc`` is read, or, if such a file is not available the climatology is calculated from the training data of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168614f0-0492-4023-a877-2866b2d70189",
   "metadata": {},
   "outputs": [],
   "source": [
    "climatology_file = Path(\"climatology.nc\")\n",
    "if climatology_file.exists():\n",
    "    climatology = xr.load_dataset(\"climatology.nc\")\n",
    "else:\n",
    "    climatology = calculate_precip_climatology(DATA_PATH / \"training_data\" / \"daily_precip\")\n",
    "    climatology.to_netcdf(\"climatology.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f700f6e6-405f-4ab8-9945-23d8ab335746",
   "metadata": {},
   "source": [
    "### Visualize predicted weekly accumulations\n",
    "\n",
    "The functions defined below visualize the baseline and model predictions together with the reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66b3da-6f35-476d-b6f9-ae32818f4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from cartopy import crs as ccrs\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from pansat.time import to_datetime\n",
    "\n",
    "def plot_predictions(\n",
    "    date: np.datetime64,\n",
    "    reference_data_path: Path,\n",
    "    prediction_paths: Dict[str, Path],\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot predicted precipitation.\n",
    "\n",
    "    Args:\n",
    "        date: The initialization data of the forecasts to visualize.\n",
    "        reference_data_path: The path containing the reference data.\n",
    "        prediction_paths: A dictionary mapping dataset names to folder containing the corresponding\n",
    "            forecast results.\n",
    "\n",
    "    Return:\n",
    "        A matplotlib.Figure object containing the visualization of the forecasts.\n",
    "    \"\"\"\n",
    "    p_height = 2 \n",
    "    p_width = 4 \n",
    "    n_rows = 1 + len(prediction_paths)\n",
    "\n",
    "    fig = plt.figure(figsize=(4 * p_width, n_rows * p_height))\n",
    "    gs = GridSpec(n_rows, 6, width_ratios = [0.1] + [1.0] * 4 + [0.1])\n",
    "\n",
    "    ref_data = load_reference_data(date, reference_data_path, n_days=27).resample(step=\"7D\").mean()\n",
    "    ref_data = ref_data.transpose(\"step\", \"latitude\", \"longitude\")\n",
    "    norm = LogNorm(1e-1, 1e2)\n",
    "    norm = Normalize(0, 10)\n",
    "    lats = ref_data.latitude.data\n",
    "    lat_mask = (lats > -60) * (lats < 60)\n",
    "\n",
    "    crs = ccrs.Robinson()\n",
    "    pc = ccrs.PlateCarree()\n",
    "    cmap = \"Blues\"\n",
    "\n",
    "    for week in range(4):\n",
    "        ax = fig.add_subplot(gs[0, week + 1], projection=crs)\n",
    "        lons = ref_data.longitude.data\n",
    "        lats = ref_data.latitude.data\n",
    "        ax.pcolormesh(lons, lats, ref_data.precipitation[{\"step\": week}].data, transform=pc, norm=norm, cmap=cmap)\n",
    "        ax.set_title(f\"Week {week + 1}\", loc=\"center\")\n",
    "        ax.coastlines(color=\"grey\")\n",
    "        \n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.set_axis_off()\n",
    "    ax.text(0, 0, s=\"Reference\", ha=\"center\", va=\"center\", rotation=90, fontsize=16)\n",
    "    ax.set_ylim(-2, 2)\n",
    "\n",
    "    lons = ref_data.longitude.data\n",
    "    lats = ref_data.latitude.data\n",
    "\n",
    "    for row, (name, path) in enumerate(prediction_paths.items()):\n",
    "\n",
    "        prediction_file = find_file(date, path)\n",
    "        predictions = xr.load_dataset(prediction_file)\n",
    "            \n",
    "        predictions = predictions.resample(step=\"7D\").mean()\n",
    "        #if \"latitude\" in predictions:\n",
    "        #    predictions = predictions[{\"latitude\": lat_mask}]\n",
    "        #else:\n",
    "        #    predictions = predictions[{\"y\": lat_mask}]\n",
    "        \n",
    "        for week in range(4):\n",
    "            \n",
    "            ax = fig.add_subplot(gs[1 + row, week + 1], projection=crs)\n",
    "            m = ax.pcolormesh(lons, lats, predictions.precipitation[{\"step\": week}].data, transform=pc, norm=norm, cmap=cmap)\n",
    "\n",
    "            precip_ref = ref_data.precipitation[{\"step\": week}].data\n",
    "            if \"precipitation_em\" in predictions:\n",
    "                precip_pred = predictions.precipitation_em[{\"step\": week}].data\n",
    "            else:\n",
    "                precip_pred = predictions.precipitation[{\"step\": week}].data\n",
    "            valid = np.isfinite(precip_ref) * np.isfinite(precip_pred)\n",
    "            ax.coastlines(color=\"grey\")\n",
    "            \n",
    "        ax = fig.add_subplot(gs[1 + row, 0])\n",
    "        ax.set_axis_off()\n",
    "        ax.text(0, 0, s=name, ha=\"center\", va=\"center\", rotation=90, fontsize=16)\n",
    "        ax.set_ylim(-2, 2)\n",
    "\n",
    "    cax = fig.add_subplot(gs[:, -1])\n",
    "    plt.colorbar(m, cax=cax, label=\"Mean daily accumulated precipitation [mm]\")\n",
    "\n",
    "    date = to_datetime(date)\n",
    "    fig.suptitle(date.strftime(\"%Y-%m-%d\"), fontsize=16)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1438bce-1e67-4b64-920a-4dec7d729491",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../../windset.mplstyle\")\n",
    "\n",
    "fig = plot_predictions(\n",
    "    np.datetime64(\"2020-01-09\"),\n",
    "    DATA_PATH / \"test_data\" / \"daily_precip\",\n",
    "    {\n",
    "        \"ECMWF\": DATA_PATH / \"test_data\" / \"s2s_ecmwf\",\n",
    "        \"UMKO\": DATA_PATH / \"test_data\" / \"s2s_ukmo\",\n",
    "        \"ML Forecast\": DATA_PATH / \"results\" / \"resnext_new\",\n",
    "    }\n",
    ")\n",
    "fig.savefig(\"example_predictions.png\", bbox_inches=\"tight\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467e4ad-9068-41b0-bf64-98c7456cd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cartopy import crs as ccrs\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.colors import LogNorm\n",
    "from pansat.time import to_datetime\n",
    "\n",
    "def plot_predictions_by_day(\n",
    "    date: np.datetime64,\n",
    "    reference_data_path: Path,\n",
    "    prediction_paths: Dict[str, Path],\n",
    "    n_days = 4\n",
    "):\n",
    "    p_height = 4 \n",
    "    p_width = 8 \n",
    "    n_rows = 1 + len(prediction_paths)\n",
    "\n",
    "    fig = plt.figure(figsize=(n_days * p_width, n_rows * p_height))\n",
    "    gs = GridSpec(n_rows, n_days + 2, width_ratios = [0.1] + [1.0] * n_days + [0.1])\n",
    "\n",
    "    ref_data = load_reference_data(date, reference_data_path)\n",
    "    ref_data = ref_data.transpose(\"step\", \"latitude\", \"longitude\")\n",
    "    lats = ref_data.latitude.data\n",
    "    lat_mask = (lats > -60) * (lats < 60)\n",
    "    ref_data = ref_data[{\"latitude\": lat_mask}]\n",
    "    \n",
    "    norm = LogNorm(1e-1, 1e2)\n",
    "\n",
    "    crs = ccrs.Robinson()\n",
    "    pc = ccrs.PlateCarree()\n",
    "    cmap = \"Blues\"\n",
    "\n",
    "    for day in range(n_days):\n",
    "        ax = fig.add_subplot(gs[0, day + 1], projection=crs)\n",
    "        lons = ref_data.longitude.data\n",
    "        lats = ref_data.latitude.data\n",
    "        ax.pcolormesh(lons, lats, ref_data.precipitation[{\"step\": day}].data, transform=pc, norm=norm, cmap=cmap)\n",
    "        ax.set_title(f\"Day {day + 1}\")\n",
    "        ax.coastlines(color=\"grey\")\n",
    "\n",
    "    lons = ref_data.longitude.data\n",
    "    lats = ref_data.latitude.data\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.set_axis_off()\n",
    "    ax.text(0, 0, s=\"Reference\", ha=\"center\", va=\"center\", rotation=90, fontsize=16)\n",
    "    ax.set_ylim(-2, 2)\n",
    "\n",
    "    for row, (name, path) in enumerate(prediction_paths.items()):\n",
    "\n",
    "        prediction_file = find_file(date, path)\n",
    "        predictions = xr.load_dataset(prediction_file).resample(step=\"1D\").mean()\n",
    "        if \"latitude\" in predictions:\n",
    "            predictions = predictions[{\"latitude\": lat_mask}]\n",
    "        else:\n",
    "            predictions = predictions[{\"y\": lat_mask}]\n",
    "            \n",
    "        for day in range(n_days):\n",
    "            \n",
    "            ax = fig.add_subplot(gs[1 + row, day + 1], projection=crs)\n",
    "            m = ax.pcolormesh(lons, lats, predictions.precipitation[{\"step\": day}].data, transform=pc, norm=norm, cmap=cmap)\n",
    "\n",
    "            precip_ref = ref_data.precipitation[{\"step\": day}].data\n",
    "            precip_pred = predictions.precipitation[{\"step\": day}].data\n",
    "            valid = np.isfinite(precip_ref) * np.isfinite(precip_pred)\n",
    "            corr = np.corrcoef(precip_ref[valid], precip_pred[valid])[0, 1]\n",
    "            ax.set_title(f\"Corr. coef.: {corr}\")\n",
    "            ax.coastlines(color=\"grey\")\n",
    "            \n",
    "        ax = fig.add_subplot(gs[1 + row, 0])\n",
    "        ax.set_axis_off()\n",
    "        ax.text(0, 0, s=name, ha=\"center\", va=\"center\", rotation=90, fontsize=16)\n",
    "        ax.set_ylim(-2, 2)\n",
    "\n",
    "    cax = fig.add_subplot(gs[:, -1])\n",
    "    plt.colorbar(m, cax=cax, label=\"Daily accumulated precipitation [mm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de126c-5774-434a-a83d-e0695c7271cd",
   "metadata": {},
   "source": [
    "## Numerical evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff3426-0fc0-4c18-adc6-f13df4a2c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from chimp.utils import get_date\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def evaluate_forecasts(\n",
    "    climatology: xr.Dataset,\n",
    "    reference_data_path: Path,\n",
    "    forecast_paths: Dict[str, Path],\n",
    "    weekly=False\n",
    "):\n",
    "    \"\"\"\n",
    "    This function calculates forecast bias, MSE and correlation coefficient and their spatial distributions for\n",
    "    several provided forecast results.\n",
    "    \"\"\"\n",
    "\n",
    "    n_steps = 28\n",
    "    if weekly:\n",
    "        n_steps = 4\n",
    "    \n",
    "    ref_files = sorted(list(Path(reference_data_path).glob(\"*_????????_??_??.nc\")))\n",
    "    ref_dates = set(map(lambda x: get_date(x.name), ref_files))\n",
    "    for path in forecast_paths.values():\n",
    "        print(path)\n",
    "        if isinstance(path, Path):\n",
    "            files = sorted(list(Path(path).glob(\"*_????????_??_??.nc\")))\n",
    "            dates = set(map(lambda x: get_date(x.name), files))\n",
    "            ref_dates = ref_dates.intersection(dates)\n",
    "\n",
    "    ref_dates = sorted(list(ref_dates))\n",
    "    results = {}\n",
    "    \n",
    "    for name, path in forecast_paths.items():\n",
    "\n",
    "        pred_sum = np.zeros((n_steps, 240, 576))\n",
    "        pred2_sum = np.zeros((n_steps, 240, 576))\n",
    "        target_sum = np.zeros((n_steps, 240, 576))\n",
    "        target2_sum = np.zeros((n_steps, 240, 576))\n",
    "        predtarget_sum = np.zeros((n_steps, 240, 576))\n",
    "        counts = np.zeros((n_steps, 240, 576))\n",
    "\n",
    "        for date in tqdm(sorted(list(ref_dates))):\n",
    "\n",
    "            try:\n",
    "                ref_data = load_reference_data(date, reference_data_path)\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "            if weekly:\n",
    "                ref_data = ref_data.resample(step=\"7D\").mean()\n",
    "            ref_data = ref_data.transpose(\"step\", \"latitude\", \"longitude\")\n",
    "\n",
    "            steps = ref_data.step.data\n",
    "            lons = ref_data.longitude.data\n",
    "            lats = ref_data.latitude.data\n",
    "            lat_mask = (lats > -60) * (lats < 60)\n",
    "            lats = lats[lat_mask]\n",
    "            ref_data = ref_data[{\"latitude\": lat_mask}]\n",
    "\n",
    "            times = ref_data.time + ref_data.step\n",
    "            months = times.dt.month\n",
    "            \n",
    "            if isinstance(path, xr.Dataset):\n",
    "                predictions = path\n",
    "                predictions = predictions[{\"month\": months - 1}]\n",
    "            else:\n",
    "                prediction_file = find_file(date, path)\n",
    "                predictions = xr.load_dataset(prediction_file)\n",
    "                \n",
    "            if weekly:\n",
    "                predictions = predictions.resample(step=\"7d\").mean()\n",
    "\n",
    "            if \"latitude\" in predictions:\n",
    "                predictions = predictions[{\"latitude\": lat_mask}]\n",
    "            else:\n",
    "                predictions = predictions[{\"y\": lat_mask}]\n",
    "            \n",
    "            for step in range(n_steps):\n",
    "                precip_ref = ref_data.precipitation.data[step]\n",
    "                if \"precipitation_em\" in predictions:\n",
    "                    precip_pred = predictions.precipitation_em.data[step]\n",
    "                else:\n",
    "                    precip_pred = predictions.precipitation.data[step]\n",
    "                \n",
    "                valid = np.isfinite(precip_ref) * (precip_ref >= 0.0) * np.isfinite(precip_pred)\n",
    "                pred = precip_pred\n",
    "                target = precip_ref\n",
    "    \n",
    "                pred_sum[step] += np.where(valid, pred, 0.0)\n",
    "                pred2_sum[step] += np.where(valid, pred ** 2, 0.0)\n",
    "                target_sum[step] += np.where(valid, target, 0.0)\n",
    "                target2_sum[step] += np.where(valid, target ** 2, 0.0)\n",
    "                predtarget_sum[step] += np.where(valid, pred * target, 0.0)\n",
    "                counts[step] += valid.astype(\"float32\")\n",
    "\n",
    "        pred_mean = pred_sum / counts\n",
    "        target_mean = target_sum / counts\n",
    "        pred_var = pred2_sum / counts - pred_mean ** 2\n",
    "        target_var = target2_sum / counts - target_mean ** 2\n",
    "        mse = (pred2_sum - 2.0 * predtarget_sum + target2_sum) / counts\n",
    "        corr = (predtarget_sum / counts - pred_mean * target_mean) / np.sqrt(pred_var * target_var)\n",
    "        bias = pred_mean - target_mean\n",
    "\n",
    "        weights = np.broadcast_to(np.cos(np.deg2rad(lats))[..., None], pred_mean.shape).copy()\n",
    "        print(weights.min(), weights.max())\n",
    "\n",
    "        step_counts = (weights * counts).sum(axis=(1, 2))\n",
    "        \n",
    "        pred_mean_tot = (weights * pred_sum).sum(axis=(1, 2)) / step_counts\n",
    "        target_mean_tot = (weights * target_sum).sum(axis=(1, 2)) / step_counts\n",
    "        pred_var_tot = (weights * pred2_sum).sum(axis=(1, 2)) / step_counts - pred_mean_tot ** 2\n",
    "        target_var_tot = (weights * target2_sum).sum(axis=(1, 2)) / step_counts - target_mean_tot ** 2\n",
    "        mse_tot = (weights * (pred2_sum - 2.0 * predtarget_sum + target2_sum)).sum(axis=(1, 2)) / step_counts\n",
    "        corr_tot = ((weights * predtarget_sum).sum(axis=(1, 2)) / step_counts - pred_mean_tot * target_mean_tot) / np.sqrt(pred_var_tot * target_var_tot)\n",
    "        bias_tot = pred_mean_tot - target_mean_tot\n",
    "\n",
    "        results[name] = xr.Dataset({\n",
    "            \"latitude\": ((\"latitude\",), lats),\n",
    "            \"longitude\": ((\"longitude\"), lons),\n",
    "            \"step\": ((\"step\"), steps),\n",
    "            \"bias\": ((\"step\", \"latitude\", \"longitude\"), bias),\n",
    "            \"correlation_coef\": ((\"step\", \"latitude\", \"longitude\"), corr),\n",
    "            \"mean_squared_error\": ((\"step\", \"latitude\", \"longitude\"), mse),\n",
    "            \"bias_tot\": ((\"step\",), bias_tot),\n",
    "            \"correlation_coef_tot\": ((\"step\",), corr_tot),\n",
    "            \"mean_squared_error_tot\": ((\"step\",), mse_tot)\n",
    "        })\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a63990-4199-4d88-833f-1c4f9a7f4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1700a6c-2646-4404-afe8-65ced1acf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_forecasts(\n",
    "    climatology,\n",
    "    DATA_PATH / \"test_data\" / \"daily_precip\",\n",
    "    {\n",
    "        \"Climatology\": climatology,\n",
    "        \"ECMWF\": DATA_PATH / \"test_data\" / \"s2s_ecmwf\",\n",
    "        \"UKMO\": DATA_PATH / \"test_data\" / \"s2s_ukmo\",\n",
    "        \"resnext-16\": DATA_PATH / \"results\" / \"resnext_new\"\n",
    "    },\n",
    "    weekly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cb57f-cc4d-4f5b-876e-cfd42b2686f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "mpl.style.use(\"../../windset.mplstyle\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "gs = GridSpec(1, 4, width_ratios=[1.0, 1.0, 1.0, 0.3], wspace=0.3)\n",
    "lead_time = np.arange(1, 29)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "#ax.plot(lead_time, results[\"ECMWF\"].bias_tot)\n",
    "#ax.plot(lead_time, results[\"UKMO\"].bias_tot)\n",
    "ax.plot(lead_time, results[\"resnext-16\"].bias_tot)\n",
    "ax.plot(lead_time, results[\"Climatology\"].bias_tot, c=\"k\", ls=\"--\")\n",
    "ax.set_xlabel(\"Lead time [d]\")\n",
    "ax.set_ylabel(\"Bias [mm]\")\n",
    "ax.set_title(\"(a) Bias\", loc=\"left\")\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "ax.set_xlim(0, 28)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 1])\n",
    "ax.plot(lead_time, results[\"ECMWF\"].correlation_coef_tot, label=\"ecmwf\")\n",
    "ax.plot(lead_time, results[\"UKMO\"].correlation_coef_tot, label=\"UK\")\n",
    "ax.plot(lead_time, results[\"resnext-16\"].correlation_coef_tot, label=\"Neural network forecast\")\n",
    "ax.plot(lead_time, results[\"Climatology\"].correlation_coef_tot, label=\"Climatology\", c=\"k\", ls=\"--\")\n",
    "ax.set_xlabel(\"Lead time [d]\")\n",
    "ax.set_ylabel(\"Correlation coef.\",)\n",
    "ax.set_title(\"(b) Correlation coef.\", loc=\"left\")\n",
    "ax.set_ylim(0.0, 1.0)\n",
    "ax.set_xlim(0, 28)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 2])\n",
    "handles = []\n",
    "handles += ax.plot(lead_time, results[\"Climatology\"].mean_squared_error_tot, label=\"Monthly climatology\", ls=\"--\", c=\"k\")\n",
    "handles += ax.plot(lead_time, results[\"ECMWF\"].mean_squared_error_tot, label=\"ECMWF\")\n",
    "handles += ax.plot(lead_time, results[\"UKMO\"].mean_squared_error_tot, label=\"UKMO\")\n",
    "handles += ax.plot(lead_time, results[\"resnext-16\"].mean_squared_error_tot, label=\"ML forecast\")\n",
    "ax.set_xlabel(\"Lead time [d]\")\n",
    "ax.set_ylabel(\"Mean sqared error [mm$^2$]\")\n",
    "ax.set_title(\"(c) Mean squared error\", loc=\"left\")\n",
    "ax.set_xlim(0, 28)\n",
    "ax.set_ylim(50, 130)\n",
    "\n",
    "ax = fig.add_subplot(gs[0, 3])\n",
    "ax.set_axis_off()\n",
    "ax.legend(handles=handles, loc=\"center\")\n",
    "\n",
    "fig.savefig(\"ltpf_baseline_metrics.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
